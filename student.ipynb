{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: COLLINS KANYIRI MWANGI\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Veronica Isiaho\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression: Predicting King County, WA, Housing Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 BUSINESS UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Understanding the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The role assumed here is of a Data Scientist working for Neocivil Realtors. The Agency is in the business of helping homeowners buy and/or sell houses. The Agency and the homeowners reside in King County in the US State of Washington. The Agency has provided me with a dataset of house sales in King County. The task here is to model the real estate housing prices and use the model to accurately predict the housing prices based on a number of features provided within the dataset. The expectation is that, once completed, the model can be used by them as a tool in selecting properties for investment in King County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Analysis Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis will seek to answer three questions about the data:\n",
    "\n",
    "     Question 1: Which features are most highly correlated with price?\n",
    "\n",
    "     Question 2: Which features have the strongest correlations with other predictor variables?\n",
    "\n",
    "     Question 3: What combinations of features is the best fit, in terms of predictive power, for a multiple regression model to                  predict house prices based on provided historical data?\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 DATA UNDERSTANDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id - unique identified for a house\n",
    "\n",
    "date - Date house was sold\n",
    "\n",
    "price - Price is prediction target\n",
    "\n",
    "bedroomsNumber - of Bedrooms/House\n",
    "\n",
    "bathroomsNumber - of bathrooms/bedrooms\n",
    "\n",
    "sqft_livingsquare - footage of the home\n",
    "\n",
    "sqft_lotsquare - footage of the lot\n",
    "\n",
    "floorsTotal - floors (levels) in house\n",
    "\n",
    "waterfront - House which has a view to a waterfront\n",
    "\n",
    "view - Has been viewed\n",
    "\n",
    "condition - How good the condition is ( Overall )\n",
    "\n",
    "grade - overall grade given to the housing unit, based on King County grading system\n",
    "\n",
    "sqft_above - square footage of house apart from basement\n",
    "\n",
    "sqft_basement - square footage of the basement\n",
    "\n",
    "yr_built - Built Year\n",
    "\n",
    "yr_renovated - Year when house was renovated\n",
    "\n",
    "zipcode - zip\n",
    "\n",
    "lat - Latitude coordinate\n",
    "\n",
    "long - Longitude coordinate\n",
    "\n",
    "sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "\n",
    "sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 DATA PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load and Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>10/13/2014</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>2170</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>2/25/2015</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>6 Low Average</td>\n",
       "      <td>770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>12/9/2014</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1050</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>2/18/2015</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1680</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21592</th>\n",
       "      <td>263000018</td>\n",
       "      <td>5/21/2014</td>\n",
       "      <td>360000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21593</th>\n",
       "      <td>6600060120</td>\n",
       "      <td>2/23/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>2310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21594</th>\n",
       "      <td>1523300141</td>\n",
       "      <td>6/23/2014</td>\n",
       "      <td>402101.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21595</th>\n",
       "      <td>291310100</td>\n",
       "      <td>1/16/2015</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>8 Good</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21596</th>\n",
       "      <td>1523300157</td>\n",
       "      <td>10/15/2014</td>\n",
       "      <td>325000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>NONE</td>\n",
       "      <td>...</td>\n",
       "      <td>7 Average</td>\n",
       "      <td>1020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21597 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id        date     price  bedrooms  bathrooms  sqft_living   \n",
       "0      7129300520  10/13/2014  221900.0         3       1.00         1180  \\\n",
       "1      6414100192   12/9/2014  538000.0         3       2.25         2570   \n",
       "2      5631500400   2/25/2015  180000.0         2       1.00          770   \n",
       "3      2487200875   12/9/2014  604000.0         4       3.00         1960   \n",
       "4      1954400510   2/18/2015  510000.0         3       2.00         1680   \n",
       "...           ...         ...       ...       ...        ...          ...   \n",
       "21592   263000018   5/21/2014  360000.0         3       2.50         1530   \n",
       "21593  6600060120   2/23/2015  400000.0         4       2.50         2310   \n",
       "21594  1523300141   6/23/2014  402101.0         2       0.75         1020   \n",
       "21595   291310100   1/16/2015  400000.0         3       2.50         1600   \n",
       "21596  1523300157  10/15/2014  325000.0         2       0.75         1020   \n",
       "\n",
       "       sqft_lot  floors waterfront  view  ...          grade sqft_above   \n",
       "0          5650     1.0        NaN  NONE  ...      7 Average       1180  \\\n",
       "1          7242     2.0         NO  NONE  ...      7 Average       2170   \n",
       "2         10000     1.0         NO  NONE  ...  6 Low Average        770   \n",
       "3          5000     1.0         NO  NONE  ...      7 Average       1050   \n",
       "4          8080     1.0         NO  NONE  ...         8 Good       1680   \n",
       "...         ...     ...        ...   ...  ...            ...        ...   \n",
       "21592      1131     3.0         NO  NONE  ...         8 Good       1530   \n",
       "21593      5813     2.0         NO  NONE  ...         8 Good       2310   \n",
       "21594      1350     2.0         NO  NONE  ...      7 Average       1020   \n",
       "21595      2388     2.0        NaN  NONE  ...         8 Good       1600   \n",
       "21596      1076     2.0         NO  NONE  ...      7 Average       1020   \n",
       "\n",
       "       sqft_basement yr_built  yr_renovated  zipcode      lat     long   \n",
       "0                0.0     1955           0.0    98178  47.5112 -122.257  \\\n",
       "1              400.0     1951        1991.0    98125  47.7210 -122.319   \n",
       "2                0.0     1933           NaN    98028  47.7379 -122.233   \n",
       "3              910.0     1965           0.0    98136  47.5208 -122.393   \n",
       "4                0.0     1987           0.0    98074  47.6168 -122.045   \n",
       "...              ...      ...           ...      ...      ...      ...   \n",
       "21592            0.0     2009           0.0    98103  47.6993 -122.346   \n",
       "21593            0.0     2014           0.0    98146  47.5107 -122.362   \n",
       "21594            0.0     2009           0.0    98144  47.5944 -122.299   \n",
       "21595            0.0     2004           0.0    98027  47.5345 -122.069   \n",
       "21596            0.0     2008           0.0    98144  47.5941 -122.299   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "0               1340        5650  \n",
       "1               1690        7639  \n",
       "2               2720        8062  \n",
       "3               1360        5000  \n",
       "4               1800        7503  \n",
       "...              ...         ...  \n",
       "21592           1530        1509  \n",
       "21593           1830        7200  \n",
       "21594           1020        2007  \n",
       "21595           1410        1287  \n",
       "21596           1020        1357  \n",
       "\n",
       "[21597 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('data/kc_house_data.csv')\n",
    "# Preview of the first and last rows of the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21597 entries, 0 to 21596\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21597 non-null  int64  \n",
      " 1   date           21597 non-null  object \n",
      " 2   price          21597 non-null  float64\n",
      " 3   bedrooms       21597 non-null  int64  \n",
      " 4   bathrooms      21597 non-null  float64\n",
      " 5   sqft_living    21597 non-null  int64  \n",
      " 6   sqft_lot       21597 non-null  int64  \n",
      " 7   floors         21597 non-null  float64\n",
      " 8   waterfront     19221 non-null  object \n",
      " 9   view           21534 non-null  object \n",
      " 10  condition      21597 non-null  object \n",
      " 11  grade          21597 non-null  object \n",
      " 12  sqft_above     21597 non-null  int64  \n",
      " 13  sqft_basement  21597 non-null  object \n",
      " 14  yr_built       21597 non-null  int64  \n",
      " 15  yr_renovated   17755 non-null  float64\n",
      " 16  zipcode        21597 non-null  int64  \n",
      " 17  lat            21597 non-null  float64\n",
      " 18  long           21597 non-null  float64\n",
      " 19  sqft_living15  21597 non-null  int64  \n",
      " 20  sqft_lot15     21597 non-null  int64  \n",
      "dtypes: float64(6), int64(9), object(6)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checked to see the datatype, number of columns and rows of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the data types are numeric though we have a few object data types. The total number of rows is 21,597 and the number of columns in 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               21420\n",
       "date               372\n",
       "price             3622\n",
       "bedrooms            12\n",
       "bathrooms           29\n",
       "sqft_living       1034\n",
       "sqft_lot          9776\n",
       "floors               6\n",
       "waterfront           2\n",
       "view                 5\n",
       "condition            5\n",
       "grade               11\n",
       "sqft_above         942\n",
       "sqft_basement      304\n",
       "yr_built           116\n",
       "yr_renovated        70\n",
       "zipcode             70\n",
       "lat               5033\n",
       "long               751\n",
       "sqft_living15      777\n",
       "sqft_lot15        8682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checked the number of unique values for each column\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be some repeated values in the id column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a statistical summary of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count: The count of non-null values in each column. It gives you an idea of missing values or potential data quality issues.\n",
    "\n",
    "Mean: The average value of each column. It provides a measure of central tendency and can give you a sense of the typical value.\n",
    "\n",
    "Standard Deviation: The measure of the spread or variability of each column's values around the mean. It indicates how dispersed the data points are.\n",
    "\n",
    "Minimum and Maximum: The smallest and largest values in each column. It gives you the range of the data and helps identify potential outliers.\n",
    "\n",
    "Quartiles (25%, 50%, and 75%): These values divide the data into four equal parts. The 50th percentile (median) represents the middle value, while the 25th and 75th percentiles indicate the lower and upper quartiles, respectively. They provide insights into the data's distribution and skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the toal number of null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns waterfront, view and yr_renovated have 2376, 63 and 3842 null values respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A look at the percentage of missing values\n",
    "for col in df.columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        perc = (df[col].isnull().sum()/len(df[col]))*100\n",
    "        print(\"The column\", col,\"has\",df[col].isnull().sum(),\"missing values, which is\", round(perc, 1),\"% of it's total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfront Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['waterfront'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values are nan, NO and YES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['waterfront'].value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common value in this column is NO with 19075 entries while YES has only 146. This means most of these houses don't have a waterfront hence it's safe to assume that the ones with missing values also don't have a waterfront. Therefore, I will replace the missing values with NO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with 'NO'\n",
    "df['waterfront'].fillna('NO',inplace=True)\n",
    "\n",
    "# confirm if the missing values have been replaced\n",
    "df['waterfront'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NO entries have increased from 19075 to 21451  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data type \n",
    "df['waterfront'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that waterfront is of type object. This is not compatible for our model hence I need to convert it to type int. Before changing the datatype, I first need to change the column to a binary column with 1 == YES and 0 == NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace the values 'NO' and 'YES' with '0' and '1' respectively\n",
    "df['waterfront'].replace({'NO': 0, 'YES': 1}, inplace=True)\n",
    "\n",
    "#convert column to data type 'int'\n",
    "df['waterfront'].astype(int)\n",
    "\n",
    "#confirm if change occured\n",
    "df['waterfront'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values have now changed to 1s and 0s and the datatype is now integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['view'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique values:\n",
    "'NONE' 'GOOD' 'EXCELLENT' 'AVERAGE' 'FAIR'\n",
    "nan -- missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['view'].value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common value in this column is NONE. So this means most of the houses don't have a view. It's safe to assume the 63 missing values also don't have a view. Therefore, I will replace the missing values with NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of missing values:\",df['view'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with 'NONE'\n",
    "df['view'].fillna('NONE',inplace=True)\n",
    "\n",
    "# confirm if the missing values have been replaced\n",
    "df['view'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 'NONE\" entries has increased from 19422 to 19485 thus showing that the missing 63 vales have been replaced by NONE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Year Renovated Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['yr_renovated'].unique(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nan also exists in the unique values of this column. The years run from 1948 to 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['yr_renovated'].value_counts(),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of distinct elements is: 70 \n",
    "The most common value in this column is 0.0.\n",
    "it's not possible to know what 0.0 stands for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values with '0.0'\n",
    "df['yr_renovated'].fillna(0.0,inplace=True)\n",
    "\n",
    "# confirm if the missing values have been replaced\n",
    "df['yr_renovated'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of missing values increased from 17011 to 20853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter checking to see if there are any more missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more missing values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion of Date Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the date into month, day and year\n",
    "date = df['date'].str.split('/', expand=True)\n",
    "\n",
    "# create new columns for month and year and convert to integer\n",
    "df['month_sold'] = date[0].astype(int)\n",
    "df['yr_sold'] = date[2].astype(int)\n",
    "\n",
    "# drop original date column\n",
    "df.drop(columns=['date'], axis=1, inplace=True)\n",
    "\n",
    "# check to see if changed were made\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert view to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make view feature 0, 1, 2, 3 or 4 instead of none, fair, average, good, excellent\n",
    "\n",
    "df.view.replace({'NONE': 0, 'FAIR': 1, 'AVERAGE': 2, 'GOOD': 3, 'EXCELLENT': 4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.view.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaced\n",
    "'NONE' with 0, 'FAIR' with 1, 'AVERAGE' with 2, 'GOOD' with 3, 'EXCELLENT' with 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert condition to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make condition feature 0, 1, 2, 3 or 4 instead of poor, fair, average, good, very good\n",
    "\n",
    "df.condition.replace({'Poor': 0, 'Fair': 1, 'Average': 2, 'Good': 3, 'Very Good': 4}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.condition.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replaced \n",
    "'Poor' with 0, 'Fair' with 1, 'Average' with 2, 'Good' with 3, 'Very Good' with 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert grade to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace grade description with the numerical grade at the beginning of the string, as an int\n",
    "\n",
    "df['grade'] = df.grade.map(lambda x: x.split(' ')[0]).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.grade.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Replace grade description with the numerical grade at the beginning of the string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conversion of sqft_basement to Float/Int Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Change column sqft_basement datatype into float\n",
    "\n",
    "df['sqft_basement'] = [float(x) if x != '?' else 0.0 for x in df['sqft_basement']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we replaced the ? with 0.0, and converted it to float type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm if change occured\n",
    "df['sqft_basement'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and deal with Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the number of unique characters in each column.\n",
    "df.nunique(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the columns with more than single digits count.\n",
    "fig, axs = plt.subplots(2,4, figsize = (15,6))\n",
    "plt1 = sns.boxplot(df['price'], ax = axs[0,0])\n",
    "plt2 = sns.boxplot(df['bedrooms'], ax = axs[0,1])\n",
    "plt3 = sns.boxplot(df['bathrooms'], ax = axs[0,2])\n",
    "plt4 = sns.boxplot(df['sqft_living'], ax = axs[0,3])\n",
    "plt5 = sns.boxplot(df['sqft_lot'], ax = axs[1,0])\n",
    "plt1 = sns.boxplot(df['floors'], ax = axs[1,1])\n",
    "plt2 = sns.boxplot(df['sqft_above'], ax = axs[1,2])\n",
    "plt3 = sns.boxplot(df['sqft_basement'], ax = axs[1,3])\n",
    "plt.savefig('./images/fig1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figures show that there are multipal columns contain some outlier data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_modify = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot','sqft_above','sqft_basement']\n",
    "for col in to_modify:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df[col] >= Q1 - 1.5*IQR) & (df[col] <= Q3 + 1.5*IQR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot them again to check the results\n",
    "# check the data after modification\n",
    "fig, axs = plt.subplots(2,4, figsize = (15,6))\n",
    "plt1 = sns.boxplot(df['price'], ax = axs[0,0])\n",
    "plt2 = sns.boxplot(df['bedrooms'], ax = axs[0,1])\n",
    "plt3 = sns.boxplot(df['bathrooms'], ax = axs[0,2])\n",
    "plt4 = sns.boxplot(df['sqft_living'], ax = axs[0,3])\n",
    "plt5 = sns.boxplot(df['sqft_lot'], ax = axs[1,0])\n",
    "plt1 = sns.boxplot(df['floors'], ax = axs[1,1])\n",
    "plt2 = sns.boxplot(df['sqft_above'], ax = axs[1,2])\n",
    "plt3 = sns.boxplot(df['sqft_basement'], ax = axs[1,3])\n",
    "plt.savefig('./images/fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirm if change occured\n",
    "df.nunique(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outlier values were removed from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the cleaned data into a csv file\n",
    "df.to_csv('data/cleaned_kchousing.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.0 STATISTICAL MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Checking Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View heatmap to get  Variable Correlations\n",
    "corr = df.corr().abs()\n",
    "fig, ax=plt.subplots(figsize=(17,12))\n",
    "fig.suptitle('Variable Correlations', fontsize=30, y=.95, fontname='DejaVu Sans')\n",
    "heatmap = sns.heatmap(corr, cmap=\"YlGnBu\", annot=True)\n",
    "plt.savefig('images/Variable Correlations heatmap');\n",
    "heatmap;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation of 0.7 to 1.0 (-0.7 to -1) suggests a strong positive (negative) linear relationship while 0.5 to 0.6 (-0.5 to -0.6) is considered moderate.\n",
    "many of the variables related to the size of homes (e.g. sqft_living, sqft_living15, etc) are strongly correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is price. Therefore, we look at the correlation coefficients for all of the predictor variables to find the one with the highest correlation with price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation of the independent variables in descending order\n",
    "df.corr()['price'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1: Which features are most highly correlated with price?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sqft_living has the strongest positive correlation with price followed by \n",
    " grade, sqft_living15, sqft_above and bathrooms in that order.\n",
    " NOTE. we do not use lat as its not needed in the analyisis\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.2 Plotting the sqft_living vs. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a scatter plot of sqft_living vs. price:\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "df.plot.scatter(x='sqft_living', y='price', ax=ax)\n",
    "plt.title('Scatter Plot of Square Footage of Living Space vs Price');\n",
    "plt.savefig('images/fig3');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Simple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setting Up Variables for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaring y and X_base variables, where y is a Series containing price data and X_base is a DataFrame containing the column with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "\n",
    "X_base = df['sqft_living']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and Fitting Simple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = sm.OLS(endog=y, exog=sm.add_constant(X_base))\n",
    "base_results = base_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate and Interpret Baseline Model Results\n",
    "print(base_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean absolute error\n",
    "base_mae = mean_absolute_error(y, base_results.predict(sm.add_constant(X_base)))\n",
    "base_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model fit\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "df.plot(x='sqft_living', y='price', kind=\"scatter\", label=\"Data points\", ax=ax)\n",
    "sm.graphics.abline_plot(model_results=base_results, label=\"Regression line (radio)\", c=\"red\", linewidth=2, ax=ax)\n",
    "ax.legend()\n",
    "plt.savefig('images/model fit');\n",
    "plt.show()\n",
    "\n",
    "#Visualize fitted values\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "sm.graphics.plot_fit(base_results, \"sqft_living\", ax=ax)\n",
    "plt.savefig('images/fitted values');\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "Our model is statistically significant overall with a Prob (F-statistic) value of 0.00 which is less than the standard alpha 0.05. The model also explains about 29% of the variance in price. A higher variance is always preferred.\n",
    "\n",
    "Both our intercept (const) and our coefficient for sqft_living are statistically significant with P>|t| values of 0.000 which are less than the standard alpha of 0.05.\n",
    "\n",
    "Our intercept is about 144200, meaning that a home with 0 square feet of living area would cost about 144200$.\n",
    "\n",
    "Our coefficient for sqft_living is about 169, which means that for each additional square foot of living area, we expect the price to increase by about 169$.\n",
    "\n",
    "A mean absolute error (MAE) of 130267.37 means that our model is off by 130267$. This means that the difference between the actual price and the predicted price is approximately 130267$ which is quite high. A lower MAE is always preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Multiple Regression Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setting Up Variables for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable representing all the highly correlated variables\n",
    "X_multiple1 = df[[\"sqft_living\", \"grade\", \"sqft_living15\", \"sqft_above\", \"bathrooms\"]]\n",
    "X_multiple1= X_multiple1.astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Categorical Variable by One Hot-Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grade column represents the overall grade given to the housing unit, based on King County grading system. In order to use this variable in a model, it needs to be transformed and this will be done by creating multiple dummy variables, one for each category of the categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the categorical column in X_iterated\n",
    "X_multiple1 = pd.get_dummies(X_multiple1, columns=['grade'])\n",
    "\n",
    "X_multiple1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the y variable from our base model and X_multiple1, we build a model called multiple1_model and a regression results object called multiple1_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple1_model = sm.OLS(y, sm.add_constant(X_multiple1))\n",
    "multiple1_results = multiple1_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluate and Interpret Multiple Linear Regression Model Results\n",
    "print(multiple1_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
